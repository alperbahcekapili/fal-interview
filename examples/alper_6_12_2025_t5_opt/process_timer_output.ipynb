{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5818931",
   "metadata": {},
   "source": [
    "This notebook is to evaluate where model has bottlenecks in terms of speed and generate ideas to adress them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f290f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer_values = {'values': {'preprocess': [0.018154144287109375], 'text_encoding': [8.436538457870483], 'image_encoding': [0.3386096954345703], 'noise_pred_cond': [0.1818675994873047, 0.1723024845123291, 0.1720283031463623, 0.1699666976928711, 0.1719205379486084, 0.17190051078796387, 0.1700129508972168, 0.17205023765563965, 0.17061376571655273, 0.1723489761352539, 0.17181801795959473, 0.1722571849822998, 0.17164087295532227, 0.17296123504638672, 0.17176270484924316, 0.17162656784057617, 0.17234325408935547, 0.17256426811218262, 0.17217516899108887, 0.17279505729675293, 0.17197299003601074, 0.1725304126739502, 0.1712343692779541, 0.1730666160583496, 0.17202448844909668, 0.17189240455627441, 0.17273712158203125, 0.17305946350097656, 0.17127227783203125, 0.1727595329284668, 0.17292213439941406, 0.17267417907714844, 0.1721346378326416, 0.1733531951904297, 0.17279362678527832, 0.17231464385986328, 0.17311573028564453, 0.1725611686706543, 0.17187070846557617, 0.1726365089416504, 0.17293024063110352, 0.17321228981018066, 0.1724720001220703, 0.1726670265197754, 0.17238140106201172, 0.17301225662231445, 0.172379732131958, 0.17210912704467773, 0.17257976531982422, 0.17279911041259766, 0.1725630760192871, 0.17185568809509277, 0.17342472076416016, 0.17234039306640625, 0.1723768711090088, 0.17324447631835938, 0.173370361328125, 0.17409777641296387, 0.17365574836730957, 0.1717374324798584], 'noise_pred_uncond': [0.1682126522064209, 0.1679372787475586, 0.16831040382385254, 0.16847634315490723, 0.16745495796203613, 0.16783428192138672, 0.16852903366088867, 0.16817784309387207, 0.16895651817321777, 0.1685338020324707, 0.16922640800476074, 0.16857624053955078, 0.16924357414245605, 0.1691286563873291, 0.16965150833129883, 0.16931438446044922, 0.16828513145446777, 0.16959547996520996, 0.16881656646728516, 0.16856122016906738, 0.16933703422546387, 0.1695101261138916, 0.1681981086730957, 0.1692662239074707, 0.16957473754882812, 0.16856908798217773, 0.16921257972717285, 0.1699824333190918, 0.16880583763122559, 0.16903042793273926, 0.1684279441833496, 0.169541597366333, 0.16892004013061523, 0.1690523624420166, 0.1697239875793457, 0.16959214210510254, 0.16920804977416992, 0.1702868938446045, 0.1688070297241211, 0.16927719116210938, 0.1687002182006836, 0.16917967796325684, 0.16936182975769043, 0.1698610782623291, 0.16928458213806152, 0.16893839836120605, 0.16959166526794434, 0.1693892478942871, 0.1696639060974121, 0.16911864280700684, 0.16849923133850098, 0.17066740989685059, 0.1701045036315918, 0.17064929008483887, 0.1701517105102539, 0.17007017135620117, 0.17046785354614258, 0.16942667961120605, 0.17069029808044434, 0.1707320213317871], 'scheduler_step': [0.0013279914855957031, 0.001497507095336914, 0.013544559478759766, 0.001577138900756836, 0.0011012554168701172, 0.0017499923706054688, 0.0015544891357421875, 0.0015642642974853516, 0.0016417503356933594, 0.0011069774627685547, 0.0015747547149658203, 0.0015664100646972656, 0.0015447139739990234, 0.0015451908111572266, 0.001544952392578125, 0.001560211181640625, 0.0010890960693359375, 0.001577138900756836, 0.0012369155883789062, 0.0015473365783691406, 0.0015621185302734375, 0.0015571117401123047, 0.001089334487915039, 0.0011143684387207031, 0.0015404224395751953, 0.0011153221130371094, 0.0015583038330078125, 0.0016393661499023438, 0.0011014938354492188, 0.0011188983917236328, 0.0010914802551269531, 0.0015556812286376953, 0.0010941028594970703, 0.0015461444854736328, 0.0015625953674316406, 0.0014946460723876953, 0.0011632442474365234, 0.0015463829040527344, 0.0012905597686767578, 0.001552581787109375, 0.0011119842529296875, 0.0015511512756347656, 0.0015497207641601562, 0.0015614032745361328, 0.001547098159790039, 0.0016994476318359375, 0.001611948013305664, 0.0016970634460449219, 0.001565694808959961, 0.0016281604766845703, 0.0016298294067382812, 0.0015652179718017578, 0.0015637874603271484, 0.0016188621520996094, 0.0015549659729003906, 0.0015676021575927734, 0.001569986343383789, 0.0015561580657958984, 0.001710653305053711, 0.0013899803161621094]}, 'avgs': [0.018154144287109375, 8.436538457870483, 0.3386096954345703, 0.1725182016690572, 0.16919490893681843, 0.0016666253407796223], 'vars': [0.0, 0.0, 0.0, 2.052726974647435e-06, 5.441238520455094e-07, 2.4299851733960365e-06]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab48ba",
   "metadata": {},
   "source": [
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18728ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00819f1a",
   "metadata": {},
   "source": [
    "First get an idea on which part is slowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936d06c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('noise_pred_cond', 10.351092100143433), ('noise_pred_uncond', 10.151694536209106), ('text_encoding', 8.436538457870483), ('image_encoding', 0.3386096954345703), ('scheduler_step', 0.09999752044677734), ('preprocess', 0.018154144287109375)]\n"
     ]
    }
   ],
   "source": [
    "values = {k:sum(v) for k,v in timer_values[\"values\"].items()}\n",
    "sorted_dict = sorted(values.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db33d948",
   "metadata": {},
   "source": [
    "This measurement has been done under the 60 step schedule. So here noise_pred_cond and noise_pred_uncond steps are the most dominant ones. But text_encoding is a big downside as well. We can directly minimize the total speed of this step by generating an tensorrt engine for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a755dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpfischer/miniconda3/envs/wan310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "TensorRT-LLM is not installed. Please install TensorRT-LLM or set TRTLLM_PLUGINS_PATH to the directory containing libnvinfer_plugin_tensorrt_llm.so to use converters for torch.distributed ops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model to cpu first\n",
      "Transfering model to cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_tensorrt\n",
    "\n",
    "from wan.utils.timer import Timer\n",
    "\n",
    "from wan.modules.t5 import T5EncoderModel\n",
    "\n",
    "# wan_shared_cfg.t5_model = 'umt5_xxl'\n",
    "# wan_shared_cfg.t5_dtype = torch.bfloat16\n",
    "# wan_shared_cfg.text_len = 512\n",
    "# ti2v_5B.t5_checkpoint = 'models_t5_umt5-xxl-enc-bf16.pth'\n",
    "# ti2v_5B.t5_tokenizer = 'google/umt5-xxl'\n",
    "\n",
    "\n",
    "print(\"Loading model to cpu first\")\n",
    "model = T5EncoderModel(\n",
    "    text_len=512, # from config\n",
    "    dtype=torch.bfloat16,\n",
    "    device=torch.device(\"cpu\"),\n",
    "    checkpoint_path=\"Wan2.2-TI2V-5B/models_t5_umt5-xxl-enc-bf16.pth\",\n",
    "    tokenizer_path=\"Wan2.2-TI2V-5B/google/umt5-xxl\"\n",
    "\n",
    ")\n",
    "print(\"Transfering model to cuda\")\n",
    "model.model.eval().to(\"cuda\")\n",
    "\n",
    "\n",
    "\n",
    "texts = [\"Alper example input\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebebb8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c79d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timer.start(\"Base-text-encoder\")\n",
    "out_base = model(texts, \"cuda\")\n",
    "timer.end(\"Base-text-encoder\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b741fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running torch tensorrt compile\n"
     ]
    }
   ],
   "source": [
    "print(\"Running torch tensorrt compile\")\n",
    "optimized_model = torch.compile(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db6a40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference a couple of time\n"
     ]
    }
   ],
   "source": [
    "print(\"Running inference a couple of time\")\n",
    "\n",
    "\n",
    "texts = [\"Alper example input\"]\n",
    "for i in range(10):\n",
    "    timer.start(\"optimized-text-encoder\")\n",
    "    out = optimized_model(texts, device=\"cuda\")\n",
    "    timer.end(\"optimized-text-encoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca281f2d",
   "metadata": {},
   "source": [
    "Compare outputs to validate compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "689011c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max diff: 0.03125, Mean diff: 0.0010833740234375\n"
     ]
    }
   ],
   "source": [
    "diff = torch.abs(out[0]-out_base[0])\n",
    "max_diff = diff.max()\n",
    "mean_diff = diff.mean()\n",
    "print(f\"Max diff: {max_diff.item()}, Mean diff: {mean_diff.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc7aa8",
   "metadata": {},
   "source": [
    "So conversion looks legit. Lets check the speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4532461d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': {'Base-text-encoder': [0.4980344772338867],\n",
       "  'optimized-text-encoder': [7.102445125579834,\n",
       "   0.09322404861450195,\n",
       "   0.0927882194519043,\n",
       "   0.09327936172485352,\n",
       "   0.09337925910949707,\n",
       "   0.09266066551208496,\n",
       "   0.09299707412719727,\n",
       "   0.09365344047546387,\n",
       "   0.09440493583679199,\n",
       "   0.09402823448181152]},\n",
       " 'avgs': [0.4980344772338867, 0.7942860364913941],\n",
       " 'vars': [0.0, 4.4214303808917785]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db1b33",
   "metadata": {},
   "source": [
    "As you can see from above we got x5 speed-up only by using torch.compile. We can add the compilation to our code directly and see if it helps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a988c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wan310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
